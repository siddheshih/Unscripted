{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SoC - Unscripted - TTS.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "uDnaS1ira55b",
        "outputId": "d0fe37f5-13c8-42bf-8805-8656d57d5f6c"
      },
      "source": [
        "# To wrap text in the output\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "KR2gNywtW4Qm",
        "outputId": "a5cc7c7e-f2b8-4e4d-d828-9c795dd42dae"
      },
      "source": [
        "# Install SpeechRecognition and jiwer libraries\n",
        "!pip install SpeechRecognition jiwer"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.7/dist-packages (3.8.1)\n",
            "Requirement already satisfied: jiwer in /usr/local/lib/python3.7/dist-packages (2.2.0)\n",
            "Requirement already satisfied: python-Levenshtein in /usr/local/lib/python3.7/dist-packages (from jiwer) (0.12.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from jiwer) (1.19.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from python-Levenshtein->jiwer) (57.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "QZHGILD4W6Z-",
        "outputId": "0b6ea5c2-08e4-41be-b14a-cea7f3be12fa"
      },
      "source": [
        "# Imports\n",
        "import speech_recognition as sr\n",
        "from jiwer import wer\n",
        "# sr.__version__"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "0H0Jl2KTaA5f",
        "outputId": "e252863d-7d7f-43eb-e0af-9903583ee3e3"
      },
      "source": [
        "# Define Ground Truth corresponding to the Welcome.wav file\n",
        "ground_truth = \"Thank you for choosing the Olympus dictation management system. The Olympus dictation management system gives you the power to manage your dictation transcriptions and documents seamlessly and to improve the productivity of your daily work for example you can automatically sends the dictation files or transcribed documents to your assistant of the Otha via email or FTP. If you are using the speech recognition software the speech recognition engine works in the background to support your document creation. We hope you enjoy the simple flexible reliable and secure solutions from Olympus.\""
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "aF6RWvDUXwjH",
        "outputId": "a1256a7f-5891-443a-d3ee-6504a8365111"
      },
      "source": [
        "# STT using Google Web Speech API - Requires internet\n",
        "r = sr.Recognizer()\n",
        "\n",
        "hellow = sr.AudioFile('Welcome.wav')\n",
        "with hellow as source:\n",
        "    audio = r.record(source)\n",
        "try:\n",
        "    s = r.recognize_google(audio)\n",
        "    print(\"Text: \"+s)\n",
        "    error = wer(ground_truth, s)\n",
        "    print(\"WER: \"+str(error))\n",
        "except Exception as e:\n",
        "    print(\"Exception: \"+str(e))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Text: thank you for choosing the Olympus dictation management system the Olympus dictation management system gives you the power to manage your dictations transcriptions and document seamlessly and to improve the productivity of your daily work for example you can automatically send the dictation files or transcribed documents do your assistant ociosa via email or fdp if you're using the speech recognition software the speech recognition engine works in the background to support your document creation we hope you enjoy the simple flexible reliable and Secure Solutions from Olympus\n",
            "WER: 0.2087912087912088\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "2ysBpGO0Y4WL",
        "outputId": "9d4dab63-0536-49b7-ac1a-85ec2f4bb123"
      },
      "source": [
        "# # STT using Bing Speech API - Requires internet and token\n",
        "# r = sr.Recognizer()\n",
        "\n",
        "# hellow = sr.AudioFile('Welcome.wav')\n",
        "# with hellow as source:\n",
        "#     audio = r.record(source)\n",
        "# try:\n",
        "#     s = r.recognize_bing(audio)\n",
        "#     print(\"Text: \"+s)\n",
        "#     error = wer(ground_truth, s)\n",
        "#     print(\"WER: \"+str(error))\n",
        "# except Exception as e:\n",
        "#     print(\"Exception: \"+str(e))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "SCAZn0WMbhXl",
        "outputId": "86ccd8b9-5e34-4485-a7e6-943004dd3f50"
      },
      "source": [
        "# # STT using Houndify - Requires internet and token\n",
        "# r = sr.Recognizer()\n",
        "\n",
        "# hellow = sr.AudioFile('Welcome.wav')\n",
        "# with hellow as source:\n",
        "#     audio = r.record(source)\n",
        "# try:\n",
        "#     s = r.recognize_houndify(audio)\n",
        "#     print(\"Text: \"+s)\n",
        "#     error = wer(ground_truth, s)\n",
        "#     print(\"WER: \"+str(error))\n",
        "# except Exception as e:\n",
        "#     print(\"Exception: \"+str(e))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "DqkugEY0bmlK",
        "outputId": "9dea56ab-cd65-4a31-fc2d-608349149066"
      },
      "source": [
        "# # STT using IBM STT - Requires internet and token\n",
        "# r = sr.Recognizer()\n",
        "\n",
        "# hellow = sr.AudioFile('Welcome.wav')\n",
        "# with hellow as source:\n",
        "#     audio = r.record(source)\n",
        "# try:\n",
        "#     s = r.recognize_ibm(audio)\n",
        "#     print(\"Text: \"+s)\n",
        "#     error = wer(ground_truth, s)\n",
        "#     print(\"WER: \"+str(error))\n",
        "# except Exception as e:\n",
        "#     print(\"Exception: \"+str(e))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "3_chclLVbr1j",
        "outputId": "8e2a9ca2-d308-448c-b394-7fb9cbc249a8"
      },
      "source": [
        "# # STT using Wit.ai - Requires internet and token\n",
        "# r = sr.Recognizer()\n",
        "\n",
        "# hellow = sr.AudioFile('Welcome.wav')\n",
        "# with hellow as source:\n",
        "#     audio = r.record(source)\n",
        "# try:\n",
        "#     s = r.recognize_wit(audio)\n",
        "#     print(\"Text: \"+s)\n",
        "#     error = wer(ground_truth, s)\n",
        "#     print(\"WER: \"+str(error))\n",
        "# except Exception as e:\n",
        "#     print(\"Exception: \"+str(e))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "HqD7kDQJb0k5",
        "outputId": "4c5fb813-654c-4a1e-a357-f49ed02f0595"
      },
      "source": [
        "# Install Pocket Sphinx\n",
        "!sudo apt-get install -qq python python-dev python-pip build-essential swig git libpulse-dev libasound2-dev\n",
        "!pip install pocketsphinx\n",
        "\n",
        "# STT using CMU Sphinx\n",
        "r = sr.Recognizer()\n",
        "\n",
        "hellow = sr.AudioFile('Welcome.wav')\n",
        "with hellow as source:\n",
        "    audio = r.record(source)\n",
        "try:\n",
        "    s = r.recognize_sphinx(audio)\n",
        "    print(\"Text: \"+s)\n",
        "    error = wer(ground_truth, s)\n",
        "    print(\"WER: \"+str(error))\n",
        "except Exception as e:\n",
        "    print(\"Exception: \"+str(e))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pocketsphinx in /usr/local/lib/python3.7/dist-packages (0.1.15)\n",
            "Text: thank you for accusing the unimpressed dictation management system the amanda's dictation management system gives you the power to manage or dictation east transcriptions and documents seamlessly and to improve the productivity of your day the work for example you could automatically send the dictation files so transcribed documents to your system dorothy bolsa by e-mail all f. d. d. if you're using the speech recognition software the speech recognition engine what's in the background to support your document creation we hope you enjoy the simple flexible reliable and suck your solutions from olympus\n",
            "WER: 0.32967032967032966\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbqBciDaeMB3"
      },
      "source": [
        ""
      ],
      "execution_count": 32,
      "outputs": []
    }
  ]
}